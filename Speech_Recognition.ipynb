{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2644,
     "status": "ok",
     "timestamp": 1587127392082,
     "user": {
      "displayName": "Khalid Alharthi",
      "photoUrl": "",
      "userId": "04469365013677735532"
     },
     "user_tz": -180
    },
    "id": "ytxhbZjiExiA",
    "outputId": "4e7bda70-5f44-4aac-af60-dd69f1bf3399"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Bidirectional, Concatenate, Embedding\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import _pickle as pickle\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oQDVl80cbNAU"
   },
   "source": [
    "Upload the training and testing set to the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xc4fav6s0C8S"
   },
   "outputs": [],
   "source": [
    "X_train_p1 = pickle.load(open('drive/My Drive/Colab Notebooks/Data/Capstone/train_MFCC_1', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyZ2hfhs0Kta"
   },
   "outputs": [],
   "source": [
    "X_train_p2 = pickle.load(open('drive/My Drive/Colab Notebooks/Data/Capstone/train_MFCC_2', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WG0fWdnd0POY"
   },
   "outputs": [],
   "source": [
    "X_train_p3 = pickle.load(open('drive/My Drive/Colab Notebooks/Data/Capstone/train_MFCC_3', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ERV5uZR9FeNJ"
   },
   "outputs": [],
   "source": [
    "X_train = X_train_p1 +X_train_p2+X_train_p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cEcAeQEWQ7T"
   },
   "outputs": [],
   "source": [
    "del X_train_p1, X_train_p2, X_train_p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 905,
     "status": "ok",
     "timestamp": 1587127405704,
     "user": {
      "displayName": "Khalid Alharthi",
      "photoUrl": "",
      "userId": "04469365013677735532"
     },
     "user_tz": -180
    },
    "id": "vMTB_OBYFeRz",
    "outputId": "5450b32a-8be9-41ba-e509-696cfe4dc187"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69962,)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "603teHit2U2G"
   },
   "outputs": [],
   "source": [
    "X_test = pickle.load(open('drive/My Drive/Colab Notebooks/Data/Capstone/Test_MFCC', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ky8tEV3HMoQi"
   },
   "source": [
    "Upload CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GkHw6az6JVVw"
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('drive/My Drive/Colab Notebooks/Data/Capstone/csv_files/cv-valid-train.csv', sep=',', encoding='ascii')\n",
    "y= pd.read_csv('drive/My Drive/Colab Notebooks/Data/Capstone/csv_files/cv-valid-test.csv', sep=',', encoding='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6q1ySwQbNLyq"
   },
   "outputs": [],
   "source": [
    "X['filename']= X['filename'].apply(lambda x: re.split(r\"(/)\", x, re.I)[2])\n",
    "y['filename']= y['filename'].apply(lambda x: re.split(r\"(/)\", x, re.I)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YqNTmrVOAVX"
   },
   "outputs": [],
   "source": [
    "y_train = X[0:len(X_train)]['text']\n",
    "y_test = y[0:len(X_test)]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xOWPZfnQPPs7"
   },
   "source": [
    "## Reshaping the data to be used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Rcu6pqnjUFR"
   },
   "outputs": [],
   "source": [
    "def input_reshape(data):\n",
    "    data_len=[]\n",
    "    t= max(len(x) for x in X_train) \n",
    "    data_1 =np.zeros((len(data), t, len(data[0][0])))\n",
    "    for row in range(len(data)):\n",
    "        data_len.append(len(data[row]))\n",
    "        for t in range(len(data[row])):\n",
    "            for ft in range(len(data[row][t])):\n",
    "                try:\n",
    "                  data_1[row][t][ft] = data[row][t][ft]\n",
    "                except:\n",
    "                  continue\n",
    "    return data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 152438,
     "status": "ok",
     "timestamp": 1587127563099,
     "user": {
      "displayName": "Khalid Alharthi",
      "photoUrl": "",
      "userId": "04469365013677735532"
     },
     "user_tz": -180
    },
    "id": "TthWT38mHKsa",
    "outputId": "0c9b4ed4-e579-46f4-bfc5-f4e29328d639"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69962, 781, 20)\n"
     ]
    }
   ],
   "source": [
    "# reshape training set\n",
    "X_train_input = input_reshape(X_train)\n",
    "print(X_train_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 159150,
     "status": "ok",
     "timestamp": 1587127571833,
     "user": {
      "displayName": "Khalid Alharthi",
      "photoUrl": "",
      "userId": "04469365013677735532"
     },
     "user_tz": -180
    },
    "id": "9G22Fq4PzVOQ",
    "outputId": "63653458-a1b0-43ab-d8df-5eaa4eecf96d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3992, 781, 20)\n"
     ]
    }
   ],
   "source": [
    "# reshape testing set\n",
    "X_test_input = input_reshape(X_test)\n",
    "print(X_test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ifldNf2b0rBE"
   },
   "outputs": [],
   "source": [
    "del X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmR01d_FT0Fg"
   },
   "source": [
    "## Text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3pP6QHJHSOMf"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    return (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 152978,
     "status": "ok",
     "timestamp": 1587127577141,
     "user": {
      "displayName": "Khalid Alharthi",
      "photoUrl": "",
      "userId": "04469365013677735532"
     },
     "user_tz": -180
    },
    "id": "-i7LYLE-gTry",
    "outputId": "45df795a-229c-46b1-adaf-8273919078aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', ' ', \"'\", 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "{'\\t': 0, '\\n': 1, ' ': 2, \"'\": 3, 'a': 4, 'b': 5, 'c': 6, 'd': 7, 'e': 8, 'f': 9, 'g': 10, 'h': 11, 'i': 12, 'j': 13, 'k': 14, 'l': 15, 'm': 16, 'n': 17, 'o': 18, 'p': 19, 'q': 20, 'r': 21, 's': 22, 't': 23, 'u': 24, 'v': 25, 'w': 26, 'x': 27, 'y': 28, 'z': 29}\n"
     ]
    }
   ],
   "source": [
    "input_texts =y_train.apply(clean_text)\n",
    "input_texts = list('\\t' + input_texts + '\\n')\n",
    "target_characters=sorted(list(set([x for x in ' '.join(input_texts)])))\n",
    "\n",
    "indexes=[(c, target_characters.index(c)) for c in target_characters]\n",
    "target_char_index = dict(indexes)\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_char_index.items())\n",
    "\n",
    "num_decoder_chars = len(target_characters)\n",
    "max_decoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "\n",
    "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_chars), dtype='float32')\n",
    "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_chars),dtype='float32')\n",
    "\n",
    "for i, text in enumerate( input_texts):\n",
    "    for t, char in enumerate(text):\n",
    "        decoder_input_data[i, t, target_char_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_char_index[char]] = 1.\n",
    "\n",
    "print(target_characters)\n",
    "print(target_char_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cu1nI2Y9WJNG"
   },
   "source": [
    "# Speech Recognition Modeling:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYNT76QwOr4C"
   },
   "outputs": [],
   "source": [
    "batch_size = 32*25\n",
    "epochs = 15\n",
    "latent_dim = 250\n",
    "num_encoder_chars=20\n",
    "train_X = X_train_input \n",
    "encoder_input_data= X_train_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XmbJcBIKeW6k"
   },
   "source": [
    "## Build Bidirectional LSTM Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1633,
     "status": "ok",
     "timestamp": 1587127994027,
     "user": {
      "displayName": "Khalid Alharthi",
      "photoUrl": "",
      "userId": "04469365013677735532"
     },
     "user_tz": -180
    },
    "id": "njPggPPajWmD",
    "outputId": "704dec48-739d-4844-96b6-091319f25014"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, None, 20)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) [(None, 500), (None, 542000      input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, None, 30)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 500)          0           bidirectional_3[0][1]            \n",
      "                                                                 bidirectional_3[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 500)          0           bidirectional_3[0][2]            \n",
      "                                                                 bidirectional_3[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, None, 500),  1062000     input_10[0][0]                   \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 30)     15030       lstm_6[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,619,030\n",
      "Trainable params: 1,619,030\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# encoder\n",
    "bi_lstm_encoder_inputs = Input(shape=(None, num_encoder_chars))\n",
    "bi_lstm_encoder = Bidirectional(LSTM(latent_dim, return_state=True))\n",
    "encoder_outputs, forward_h, forward_c, backward_h, backward_c = bi_lstm_encoder(bi_lstm_encoder_inputs)\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# decoder\n",
    "bi_lstm_decoder_inputs = Input(shape=(None, num_decoder_chars))    \n",
    "decoder_lstm = LSTM(latent_dim*2, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(bi_lstm_decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_chars, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "bi_lstm_model = Model([bi_lstm_encoder_inputs, bi_lstm_decoder_inputs], decoder_outputs)\n",
    "bi_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYPX3XGv1c4s"
   },
   "outputs": [],
   "source": [
    "# define inference encoder\n",
    "encoder_model = Model(bi_lstm_encoder_inputs, encoder_states)\n",
    "# define inference decoder\n",
    "decoder_state_input_h = Input(shape=(latent_dim*2,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim*2,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(bi_lstm_decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([bi_lstm_decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDeOfYE-eyw9"
   },
   "source": [
    "Compile and fit the bidirectional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3156438,
     "status": "error",
     "timestamp": 1587131151871,
     "user": {
      "displayName": "Khalid Alharthi",
      "photoUrl": "",
      "userId": "04469365013677735532"
     },
     "user_tz": -180
    },
    "id": "8vSvCEwQd6T1",
    "outputId": "d77bc49b-e65c-42f0-9858-2bc4836e28de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55969 samples, validate on 13993 samples\n",
      "Epoch 1/15\n",
      "55969/55969 [==============================] - 251s 4ms/step - loss: 0.7346 - accuracy: 0.0573 - val_loss: 0.6716 - val_accuracy: 0.0669\n",
      "Epoch 2/15\n",
      "55969/55969 [==============================] - 253s 5ms/step - loss: 0.6227 - accuracy: 0.0833 - val_loss: 0.5871 - val_accuracy: 0.0905\n",
      "Epoch 3/15\n",
      "55969/55969 [==============================] - 252s 5ms/step - loss: 0.5638 - accuracy: 0.0965 - val_loss: 0.5373 - val_accuracy: 0.1028\n",
      "Epoch 4/15\n",
      "55969/55969 [==============================] - 254s 5ms/step - loss: 0.5208 - accuracy: 0.1083 - val_loss: 0.4987 - val_accuracy: 0.1136\n",
      "Epoch 5/15\n",
      "55969/55969 [==============================] - 249s 4ms/step - loss: 0.4812 - accuracy: 0.1188 - val_loss: 0.4616 - val_accuracy: 0.1235\n",
      "Epoch 6/15\n",
      "55969/55969 [==============================] - 249s 4ms/step - loss: 0.4436 - accuracy: 0.1294 - val_loss: 0.4271 - val_accuracy: 0.1333\n",
      "Epoch 7/15\n",
      "55969/55969 [==============================] - 253s 5ms/step - loss: 0.4053 - accuracy: 0.1413 - val_loss: 0.3869 - val_accuracy: 0.1456\n",
      "Epoch 8/15\n",
      "55969/55969 [==============================] - 250s 4ms/step - loss: 0.3665 - accuracy: 0.1543 - val_loss: 0.3510 - val_accuracy: 0.1580\n",
      "Epoch 9/15\n",
      "55969/55969 [==============================] - 254s 5ms/step - loss: 0.3289 - accuracy: 0.1673 - val_loss: 0.3152 - val_accuracy: 0.1703\n",
      "Epoch 10/15\n",
      "55969/55969 [==============================] - 251s 4ms/step - loss: 0.2954 - accuracy: 0.1782 - val_loss: 0.2855 - val_accuracy: 0.1800\n",
      "Epoch 11/15\n",
      "55969/55969 [==============================] - 250s 4ms/step - loss: 0.2655 - accuracy: 0.1875 - val_loss: 0.2599 - val_accuracy: 0.1879\n",
      "Epoch 12/15\n",
      "55969/55969 [==============================] - 248s 4ms/step - loss: 0.2407 - accuracy: 0.1949 - val_loss: 0.2378 - val_accuracy: 0.1942\n",
      "Epoch 13/15\n",
      "31200/55969 [===============>..............] - ETA: 1:47 - loss: 0.2215 - accuracy: 0.2010"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-23c7facdd3ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           validation_split=0.2, verbose=1 )\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# optimizer='rmsprop' , 'adam\n",
    "# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# nadam = optimizers.Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
    "bi_lstm_model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "bi_lstm_model.fit([train_X, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          shuffle=True, \n",
    "          epochs=epochs,\n",
    "          validation_split=0.2, verbose=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSJMwZMkeOdS"
   },
   "source": [
    "## Bulid LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8109,
     "status": "ok",
     "timestamp": 1587121987567,
     "user": {
      "displayName": "Khalid Alharthi",
      "photoUrl": "",
      "userId": "04469365013677735532"
     },
     "user_tz": -180
    },
    "id": "NYGXGN3ROiug",
    "outputId": "67f25849-46a9-4129-8f4b-e4a772df6136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 20)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 30)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 250), (None, 271000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 250),  281000      input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 30)     7530        lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 559,530\n",
      "Trainable params: 559,530\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, num_encoder_chars))\n",
    "encoder = LSTM(latent_dim, return_state=True )\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "decoder_inputs = Input(shape=(None, num_decoder_chars))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_chars, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "lstm_model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QcLsH2Hs1kFo"
   },
   "outputs": [],
   "source": [
    "# define inference encoder\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "# define inference decoder\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sjjZUA7GeEah"
   },
   "source": [
    "Compile and fit the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22627535,
     "status": "ok",
     "timestamp": 1587098315840,
     "user": {
      "displayName": "Khalid Alharthi",
      "photoUrl": "",
      "userId": "04469365013677735532"
     },
     "user_tz": -180
    },
    "id": "esJDjddiO8ZB",
    "outputId": "37d1e79e-7b88-4abd-b48b-bacbe4c79557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55969 samples, validate on 13993 samples\n",
      "Epoch 1/150\n",
      "55969/55969 [==============================] - 180s 3ms/step - loss: 0.7323 - accuracy: 0.0576 - val_loss: 0.6636 - val_accuracy: 0.0773\n",
      "Epoch 2/150\n",
      "55969/55969 [==============================] - 177s 3ms/step - loss: 0.6252 - accuracy: 0.0832 - val_loss: 0.5931 - val_accuracy: 0.0902\n",
      "Epoch 3/150\n",
      "55969/55969 [==============================] - 178s 3ms/step - loss: 0.5709 - accuracy: 0.0943 - val_loss: 0.5501 - val_accuracy: 0.0976\n",
      "Epoch 4/150\n",
      "55969/55969 [==============================] - 177s 3ms/step - loss: 0.5380 - accuracy: 0.1034 - val_loss: 0.5211 - val_accuracy: 0.1062\n",
      "Epoch 5/150\n",
      "55969/55969 [==============================] - 178s 3ms/step - loss: 0.5083 - accuracy: 0.1116 - val_loss: 0.4912 - val_accuracy: 0.1145\n",
      "Epoch 6/150\n",
      "55969/55969 [==============================] - 177s 3ms/step - loss: 0.4802 - accuracy: 0.1191 - val_loss: 0.4659 - val_accuracy: 0.1217\n",
      "Epoch 7/150\n",
      "55969/55969 [==============================] - 177s 3ms/step - loss: 0.4540 - accuracy: 0.1262 - val_loss: 0.4441 - val_accuracy: 0.1278\n",
      "Epoch 8/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.4301 - accuracy: 0.1331 - val_loss: 0.4181 - val_accuracy: 0.1359\n",
      "Epoch 9/150\n",
      "55969/55969 [==============================] - 177s 3ms/step - loss: 0.4080 - accuracy: 0.1421 - val_loss: 0.3996 - val_accuracy: 0.1459\n",
      "Epoch 10/150\n",
      "55969/55969 [==============================] - 177s 3ms/step - loss: 0.3873 - accuracy: 0.1478 - val_loss: 0.3806 - val_accuracy: 0.1486\n",
      "Epoch 11/150\n",
      "55969/55969 [==============================] - 177s 3ms/step - loss: 0.3679 - accuracy: 0.1568 - val_loss: 0.3607 - val_accuracy: 0.1607\n",
      "Epoch 12/150\n",
      "55969/55969 [==============================] - 177s 3ms/step - loss: 0.3497 - accuracy: 0.1599 - val_loss: 0.3419 - val_accuracy: 0.1603\n",
      "Epoch 13/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.3331 - accuracy: 0.1651 - val_loss: 0.3272 - val_accuracy: 0.1657\n",
      "Epoch 14/150\n",
      "55969/55969 [==============================] - 177s 3ms/step - loss: 0.3178 - accuracy: 0.1703 - val_loss: 0.3162 - val_accuracy: 0.1694\n",
      "Epoch 15/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.3039 - accuracy: 0.1750 - val_loss: 0.3002 - val_accuracy: 0.1751\n",
      "Epoch 16/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.2916 - accuracy: 0.1790 - val_loss: 0.2933 - val_accuracy: 0.1766\n",
      "Epoch 17/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.2802 - accuracy: 0.1828 - val_loss: 0.2806 - val_accuracy: 0.1817\n",
      "Epoch 18/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.2699 - accuracy: 0.1861 - val_loss: 0.2728 - val_accuracy: 0.1842\n",
      "Epoch 19/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.2605 - accuracy: 0.1889 - val_loss: 0.2642 - val_accuracy: 0.1864\n",
      "Epoch 20/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.2520 - accuracy: 0.1919 - val_loss: 0.2541 - val_accuracy: 0.1907\n",
      "Epoch 21/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.2440 - accuracy: 0.1943 - val_loss: 0.2511 - val_accuracy: 0.1917\n",
      "Epoch 22/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.2369 - accuracy: 0.1966 - val_loss: 0.2417 - val_accuracy: 0.1942\n",
      "Epoch 23/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.2305 - accuracy: 0.1987 - val_loss: 0.2399 - val_accuracy: 0.1950\n",
      "Epoch 24/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.2245 - accuracy: 0.2008 - val_loss: 0.2313 - val_accuracy: 0.1972\n",
      "Epoch 25/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.2186 - accuracy: 0.2036 - val_loss: 0.2260 - val_accuracy: 0.2009\n",
      "Epoch 26/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.2136 - accuracy: 0.2051 - val_loss: 0.2199 - val_accuracy: 0.2011\n",
      "Epoch 27/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.2086 - accuracy: 0.2069 - val_loss: 0.2180 - val_accuracy: 0.2050\n",
      "Epoch 28/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.2042 - accuracy: 0.2084 - val_loss: 0.2137 - val_accuracy: 0.2038\n",
      "Epoch 29/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.2000 - accuracy: 0.2097 - val_loss: 0.2084 - val_accuracy: 0.2055\n",
      "Epoch 30/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1960 - accuracy: 0.2112 - val_loss: 0.2049 - val_accuracy: 0.2088\n",
      "Epoch 31/150\n",
      "55969/55969 [==============================] - 172s 3ms/step - loss: 0.1920 - accuracy: 0.2132 - val_loss: 0.2057 - val_accuracy: 0.2082\n",
      "Epoch 32/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1885 - accuracy: 0.2129 - val_loss: 0.2034 - val_accuracy: 0.2077\n",
      "Epoch 33/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1852 - accuracy: 0.2138 - val_loss: 0.1978 - val_accuracy: 0.2086\n",
      "Epoch 34/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1821 - accuracy: 0.2149 - val_loss: 0.1967 - val_accuracy: 0.2105\n",
      "Epoch 35/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1794 - accuracy: 0.2156 - val_loss: 0.1890 - val_accuracy: 0.2126\n",
      "Epoch 36/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1763 - accuracy: 0.2169 - val_loss: 0.1926 - val_accuracy: 0.2109\n",
      "Epoch 37/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.1736 - accuracy: 0.2171 - val_loss: 0.1883 - val_accuracy: 0.2117\n",
      "Epoch 38/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1712 - accuracy: 0.2174 - val_loss: 0.1841 - val_accuracy: 0.2133\n",
      "Epoch 39/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1688 - accuracy: 0.2181 - val_loss: 0.1841 - val_accuracy: 0.2128\n",
      "Epoch 40/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1664 - accuracy: 0.2188 - val_loss: 0.1861 - val_accuracy: 0.2116\n",
      "Epoch 41/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1643 - accuracy: 0.2193 - val_loss: 0.1782 - val_accuracy: 0.2156\n",
      "Epoch 42/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1623 - accuracy: 0.2200 - val_loss: 0.1778 - val_accuracy: 0.2145\n",
      "Epoch 43/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1602 - accuracy: 0.2203 - val_loss: 0.1791 - val_accuracy: 0.2140\n",
      "Epoch 44/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.1584 - accuracy: 0.2208 - val_loss: 0.1715 - val_accuracy: 0.2165\n",
      "Epoch 45/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1564 - accuracy: 0.2215 - val_loss: 0.1702 - val_accuracy: 0.2171\n",
      "Epoch 46/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1548 - accuracy: 0.2217 - val_loss: 0.1784 - val_accuracy: 0.2138\n",
      "Epoch 47/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1532 - accuracy: 0.2220 - val_loss: 0.1723 - val_accuracy: 0.2160\n",
      "Epoch 48/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1516 - accuracy: 0.2224 - val_loss: 0.1675 - val_accuracy: 0.2171\n",
      "Epoch 49/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1500 - accuracy: 0.2229 - val_loss: 0.1673 - val_accuracy: 0.2173\n",
      "Epoch 50/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1487 - accuracy: 0.2230 - val_loss: 0.1652 - val_accuracy: 0.2181\n",
      "Epoch 51/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1470 - accuracy: 0.2235 - val_loss: 0.1661 - val_accuracy: 0.2175\n",
      "Epoch 52/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1456 - accuracy: 0.2239 - val_loss: 0.1622 - val_accuracy: 0.2193\n",
      "Epoch 53/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1446 - accuracy: 0.2241 - val_loss: 0.1627 - val_accuracy: 0.2182\n",
      "Epoch 54/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1431 - accuracy: 0.2245 - val_loss: 0.1653 - val_accuracy: 0.2171\n",
      "Epoch 55/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1419 - accuracy: 0.2248 - val_loss: 0.1625 - val_accuracy: 0.2181\n",
      "Epoch 56/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1410 - accuracy: 0.2250 - val_loss: 0.1643 - val_accuracy: 0.2178\n",
      "Epoch 57/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1396 - accuracy: 0.2254 - val_loss: 0.1554 - val_accuracy: 0.2209\n",
      "Epoch 58/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1385 - accuracy: 0.2257 - val_loss: 0.1556 - val_accuracy: 0.2205\n",
      "Epoch 59/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1377 - accuracy: 0.2259 - val_loss: 0.1500 - val_accuracy: 0.2226\n",
      "Epoch 60/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.1366 - accuracy: 0.2261 - val_loss: 0.1529 - val_accuracy: 0.2216\n",
      "Epoch 61/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1354 - accuracy: 0.2264 - val_loss: 0.1486 - val_accuracy: 0.2228\n",
      "Epoch 62/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1344 - accuracy: 0.2267 - val_loss: 0.1496 - val_accuracy: 0.2224\n",
      "Epoch 63/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1336 - accuracy: 0.2269 - val_loss: 0.1505 - val_accuracy: 0.2217\n",
      "Epoch 64/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1326 - accuracy: 0.2272 - val_loss: 0.1469 - val_accuracy: 0.2233\n",
      "Epoch 65/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1317 - accuracy: 0.2274 - val_loss: 0.1563 - val_accuracy: 0.2198\n",
      "Epoch 66/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1311 - accuracy: 0.2275 - val_loss: 0.1544 - val_accuracy: 0.2205\n",
      "Epoch 67/150\n",
      "55969/55969 [==============================] - 177s 3ms/step - loss: 0.1298 - accuracy: 0.2278 - val_loss: 0.1475 - val_accuracy: 0.2230\n",
      "Epoch 68/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.1294 - accuracy: 0.2280 - val_loss: 0.1502 - val_accuracy: 0.2222\n",
      "Epoch 69/150\n",
      "55969/55969 [==============================] - 177s 3ms/step - loss: 0.1285 - accuracy: 0.2282 - val_loss: 0.1453 - val_accuracy: 0.2237\n",
      "Epoch 70/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.1277 - accuracy: 0.2284 - val_loss: 0.1467 - val_accuracy: 0.2230\n",
      "Epoch 71/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.1270 - accuracy: 0.2285 - val_loss: 0.1420 - val_accuracy: 0.2247\n",
      "Epoch 72/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.1262 - accuracy: 0.2287 - val_loss: 0.1452 - val_accuracy: 0.2233\n",
      "Epoch 73/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.1254 - accuracy: 0.2290 - val_loss: 0.1514 - val_accuracy: 0.2211\n",
      "Epoch 74/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.1250 - accuracy: 0.2290 - val_loss: 0.1472 - val_accuracy: 0.2225\n",
      "Epoch 75/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.1242 - accuracy: 0.2292 - val_loss: 0.1375 - val_accuracy: 0.2259\n",
      "Epoch 76/150\n",
      "55969/55969 [==============================] - 177s 3ms/step - loss: 0.1233 - accuracy: 0.2295 - val_loss: 0.1498 - val_accuracy: 0.2215\n",
      "Epoch 77/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.1231 - accuracy: 0.2295 - val_loss: 0.1376 - val_accuracy: 0.2259\n",
      "Epoch 78/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.1222 - accuracy: 0.2298 - val_loss: 0.1403 - val_accuracy: 0.2249\n",
      "Epoch 79/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.1215 - accuracy: 0.2300 - val_loss: 0.1427 - val_accuracy: 0.2240\n",
      "Epoch 80/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.1210 - accuracy: 0.2300 - val_loss: 0.1386 - val_accuracy: 0.2255\n",
      "Epoch 81/150\n",
      "55969/55969 [==============================] - 177s 3ms/step - loss: 0.1205 - accuracy: 0.2302 - val_loss: 0.1368 - val_accuracy: 0.2259\n",
      "Epoch 82/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.1197 - accuracy: 0.2304 - val_loss: 0.1444 - val_accuracy: 0.2231\n",
      "Epoch 83/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1193 - accuracy: 0.2305 - val_loss: 0.1414 - val_accuracy: 0.2242\n",
      "Epoch 84/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1188 - accuracy: 0.2306 - val_loss: 0.1393 - val_accuracy: 0.2250\n",
      "Epoch 85/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1181 - accuracy: 0.2308 - val_loss: 0.1356 - val_accuracy: 0.2262\n",
      "Epoch 86/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1177 - accuracy: 0.2308 - val_loss: 0.1399 - val_accuracy: 0.2245\n",
      "Epoch 87/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1172 - accuracy: 0.2310 - val_loss: 0.1375 - val_accuracy: 0.2256\n",
      "Epoch 88/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1168 - accuracy: 0.2311 - val_loss: 0.1491 - val_accuracy: 0.2212\n",
      "Epoch 89/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1161 - accuracy: 0.2312 - val_loss: 0.1460 - val_accuracy: 0.2222\n",
      "Epoch 90/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1156 - accuracy: 0.2314 - val_loss: 0.1419 - val_accuracy: 0.2239\n",
      "Epoch 91/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1151 - accuracy: 0.2315 - val_loss: 0.1369 - val_accuracy: 0.2257\n",
      "Epoch 92/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1152 - accuracy: 0.2314 - val_loss: 0.1350 - val_accuracy: 0.2261\n",
      "Epoch 93/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1141 - accuracy: 0.2318 - val_loss: 0.1353 - val_accuracy: 0.2262\n",
      "Epoch 94/150\n",
      "55969/55969 [==============================] - 178s 3ms/step - loss: 0.1139 - accuracy: 0.2318 - val_loss: 0.1316 - val_accuracy: 0.2273\n",
      "Epoch 95/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1135 - accuracy: 0.2319 - val_loss: 0.1286 - val_accuracy: 0.2281\n",
      "Epoch 96/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1130 - accuracy: 0.2320 - val_loss: 0.1333 - val_accuracy: 0.2267\n",
      "Epoch 97/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1129 - accuracy: 0.2320 - val_loss: 0.1274 - val_accuracy: 0.2285\n",
      "Epoch 98/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1120 - accuracy: 0.2323 - val_loss: 0.1345 - val_accuracy: 0.2261\n",
      "Epoch 99/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1120 - accuracy: 0.2322 - val_loss: 0.1362 - val_accuracy: 0.2253\n",
      "Epoch 100/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1112 - accuracy: 0.2324 - val_loss: 0.1380 - val_accuracy: 0.2248\n",
      "Epoch 101/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1111 - accuracy: 0.2324 - val_loss: 0.1336 - val_accuracy: 0.2264\n",
      "Epoch 102/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1107 - accuracy: 0.2325 - val_loss: 0.1305 - val_accuracy: 0.2275\n",
      "Epoch 103/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1104 - accuracy: 0.2326 - val_loss: 0.1295 - val_accuracy: 0.2277\n",
      "Epoch 104/150\n",
      "55969/55969 [==============================] - 177s 3ms/step - loss: 0.1098 - accuracy: 0.2328 - val_loss: 0.1418 - val_accuracy: 0.2232\n",
      "Epoch 105/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1098 - accuracy: 0.2327 - val_loss: 0.1303 - val_accuracy: 0.2273\n",
      "Epoch 106/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1093 - accuracy: 0.2329 - val_loss: 0.1243 - val_accuracy: 0.2294\n",
      "Epoch 107/150\n",
      "55969/55969 [==============================] - 177s 3ms/step - loss: 0.1087 - accuracy: 0.2331 - val_loss: 0.1291 - val_accuracy: 0.2278\n",
      "Epoch 108/150\n",
      "55969/55969 [==============================] - 178s 3ms/step - loss: 0.1086 - accuracy: 0.2331 - val_loss: 0.1253 - val_accuracy: 0.2287\n",
      "Epoch 109/150\n",
      "55969/55969 [==============================] - 173s 3ms/step - loss: 0.1080 - accuracy: 0.2331 - val_loss: 0.1367 - val_accuracy: 0.2251\n",
      "Epoch 110/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1080 - accuracy: 0.2332 - val_loss: 0.1293 - val_accuracy: 0.2276\n",
      "Epoch 111/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1071 - accuracy: 0.2334 - val_loss: 0.1334 - val_accuracy: 0.2262\n",
      "Epoch 112/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.1075 - accuracy: 0.2332 - val_loss: 0.1294 - val_accuracy: 0.2275\n",
      "Epoch 113/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1072 - accuracy: 0.2333 - val_loss: 0.1242 - val_accuracy: 0.2293\n",
      "Epoch 114/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.1068 - accuracy: 0.2334 - val_loss: 0.1239 - val_accuracy: 0.2293\n",
      "Epoch 115/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.1062 - accuracy: 0.2336 - val_loss: 0.1278 - val_accuracy: 0.2280\n",
      "Epoch 116/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1062 - accuracy: 0.2335 - val_loss: 0.1244 - val_accuracy: 0.2291\n",
      "Epoch 117/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.1057 - accuracy: 0.2337 - val_loss: 0.1227 - val_accuracy: 0.2297\n",
      "Epoch 118/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.1054 - accuracy: 0.2338 - val_loss: 0.1296 - val_accuracy: 0.2274\n",
      "Epoch 119/150\n",
      "55969/55969 [==============================] - 179s 3ms/step - loss: 0.1056 - accuracy: 0.2337 - val_loss: 0.1241 - val_accuracy: 0.2291\n",
      "Epoch 120/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.1051 - accuracy: 0.2338 - val_loss: 0.1202 - val_accuracy: 0.2305\n",
      "Epoch 121/150\n",
      "55969/55969 [==============================] - 179s 3ms/step - loss: 0.1045 - accuracy: 0.2340 - val_loss: 0.1277 - val_accuracy: 0.2279\n",
      "Epoch 122/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.1040 - accuracy: 0.2341 - val_loss: 0.1239 - val_accuracy: 0.2293\n",
      "Epoch 123/150\n",
      "55969/55969 [==============================] - 178s 3ms/step - loss: 0.1044 - accuracy: 0.2340 - val_loss: 0.1238 - val_accuracy: 0.2292\n",
      "Epoch 124/150\n",
      "55969/55969 [==============================] - 179s 3ms/step - loss: 0.1035 - accuracy: 0.2342 - val_loss: 0.1227 - val_accuracy: 0.2295\n",
      "Epoch 125/150\n",
      "55969/55969 [==============================] - 180s 3ms/step - loss: 0.1036 - accuracy: 0.2342 - val_loss: 0.1312 - val_accuracy: 0.2266\n",
      "Epoch 126/150\n",
      "55969/55969 [==============================] - 182s 3ms/step - loss: 0.1033 - accuracy: 0.2343 - val_loss: 0.1273 - val_accuracy: 0.2279\n",
      "Epoch 127/150\n",
      "55969/55969 [==============================] - 181s 3ms/step - loss: 0.1031 - accuracy: 0.2343 - val_loss: 0.1354 - val_accuracy: 0.2251\n",
      "Epoch 128/150\n",
      "55969/55969 [==============================] - 182s 3ms/step - loss: 0.1032 - accuracy: 0.2343 - val_loss: 0.1232 - val_accuracy: 0.2293\n",
      "Epoch 129/150\n",
      "55969/55969 [==============================] - 178s 3ms/step - loss: 0.1026 - accuracy: 0.2344 - val_loss: 0.1184 - val_accuracy: 0.2309\n",
      "Epoch 130/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.1024 - accuracy: 0.2345 - val_loss: 0.1314 - val_accuracy: 0.2265\n",
      "Epoch 131/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.1019 - accuracy: 0.2346 - val_loss: 0.1234 - val_accuracy: 0.2293\n",
      "Epoch 132/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.1020 - accuracy: 0.2345 - val_loss: 0.1203 - val_accuracy: 0.2303\n",
      "Epoch 133/150\n",
      "55969/55969 [==============================] - 181s 3ms/step - loss: 0.1017 - accuracy: 0.2347 - val_loss: 0.1223 - val_accuracy: 0.2295\n",
      "Epoch 134/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.1015 - accuracy: 0.2347 - val_loss: 0.1253 - val_accuracy: 0.2287\n",
      "Epoch 135/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.1012 - accuracy: 0.2348 - val_loss: 0.1247 - val_accuracy: 0.2288\n",
      "Epoch 136/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.1012 - accuracy: 0.2348 - val_loss: 0.1193 - val_accuracy: 0.2306\n",
      "Epoch 137/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.1005 - accuracy: 0.2350 - val_loss: 0.1201 - val_accuracy: 0.2302\n",
      "Epoch 138/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.1003 - accuracy: 0.2350 - val_loss: 0.1167 - val_accuracy: 0.2314\n",
      "Epoch 139/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.1003 - accuracy: 0.2350 - val_loss: 0.1206 - val_accuracy: 0.2301\n",
      "Epoch 140/150\n",
      "55969/55969 [==============================] - 176s 3ms/step - loss: 0.1003 - accuracy: 0.2350 - val_loss: 0.1274 - val_accuracy: 0.2277\n",
      "Epoch 141/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.0995 - accuracy: 0.2352 - val_loss: 0.1251 - val_accuracy: 0.2285\n",
      "Epoch 142/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.1001 - accuracy: 0.2350 - val_loss: 0.1222 - val_accuracy: 0.2296\n",
      "Epoch 143/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.0996 - accuracy: 0.2352 - val_loss: 0.1313 - val_accuracy: 0.2265\n",
      "Epoch 144/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.0990 - accuracy: 0.2353 - val_loss: 0.1223 - val_accuracy: 0.2294\n",
      "Epoch 145/150\n",
      "55969/55969 [==============================] - 178s 3ms/step - loss: 0.0993 - accuracy: 0.2352 - val_loss: 0.1212 - val_accuracy: 0.2298\n",
      "Epoch 146/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.0991 - accuracy: 0.2353 - val_loss: 0.1166 - val_accuracy: 0.2314\n",
      "Epoch 147/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.0986 - accuracy: 0.2354 - val_loss: 0.1132 - val_accuracy: 0.2324\n",
      "Epoch 148/150\n",
      "55969/55969 [==============================] - 174s 3ms/step - loss: 0.0985 - accuracy: 0.2354 - val_loss: 0.1257 - val_accuracy: 0.2280\n",
      "Epoch 149/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.0984 - accuracy: 0.2354 - val_loss: 0.1184 - val_accuracy: 0.2305\n",
      "Epoch 150/150\n",
      "55969/55969 [==============================] - 175s 3ms/step - loss: 0.0980 - accuracy: 0.2356 - val_loss: 0.1159 - val_accuracy: 0.2314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb30da20c88>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizer='rmsprop' , 'adam\n",
    "# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# nadam = optimizers.Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
    "lstm_model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "lstm_model.fit([train_X, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          shuffle=True, \n",
    "          epochs=epochs,\n",
    "          validation_split=0.2, verbose=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z_PDg4AGptey"
   },
   "source": [
    "## Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1131,
     "status": "ok",
     "timestamp": 1587131171256,
     "user": {
      "displayName": "Khalid Alharthi",
      "photoUrl": "",
      "userId": "04469365013677735532"
     },
     "user_tz": -180
    },
    "id": "mumVDYso9VH5",
    "outputId": "9d38baa0-accf-48ee-93f9-59b48aa3c4d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/Data/Capstone/Models\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My Drive/Colab Notebooks/Data/Capstone/Models/ \n",
    "# pickle.dump(lstm_model, open('SR_s2s_E150_B640_L250_2', 'wb'))\n",
    "pickle.dump(bi_lstm_model, open('SR_s2s_Bi_E50_B640_L200', 'wb'))\n",
    "# model = pickle.load(open('SR_s2s_E150_B640_L250', 'rb'))\n",
    "# model = pickle.load(open('SR_s2s_Bi_E50_B640_L200', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9eYYF6p4fFyx"
   },
   "source": [
    "## Decode the sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZhunpAYjuTS"
   },
   "outputs": [],
   "source": [
    "def decode_sequence_range(seq_index_range, encoder_model, decoder_model):\n",
    "    for seq_index in range(seq_index_range):\n",
    "      input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "\n",
    "      # Encode the input as state vectors.\n",
    "      states_value = encoder_model.predict(input_seq)\n",
    "      target_seq = np.zeros((1, 1, num_decoder_chars))\n",
    "      target_seq[0, 0, target_char_index['\\t']] = 1. \n",
    "\n",
    "      # Sampling loop for a batch of sequences\n",
    "      # (to simplify, here we assume a batch of size 1).\n",
    "      stop_condition = False\n",
    "      decoded_sentence = ''\n",
    "      while not stop_condition:\n",
    "          output_tokens, h, c = decoder_model.predict(\n",
    "              [target_seq] + states_value)\n",
    "          # Update states\n",
    "          states_value = [h, c]\n",
    "\n",
    "          # Sample a char\n",
    "          sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "          sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "          decoded_sentence += sampled_char\n",
    "\n",
    "          # Update the target sequence\n",
    "          target_seq = np.zeros((1, 1, num_decoder_chars))\n",
    "          target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "          if (sampled_char == '\\n'):\n",
    "              stop_condition = True\n",
    "      return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B5uH__5RmGDO"
   },
   "outputs": [],
   "source": [
    "decoded_sentence = decode_sequence_range(10, encoder_model, decoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vpre-xwSYi2f"
   },
   "outputs": [],
   "source": [
    "for sentence in range(len(decoded_sentence)):\n",
    "    print('-'*100)\n",
    "    print('Input sentence:', input_texts[sentence])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fe3gPXifXNa4"
   },
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FywGg8YnXM4T"
   },
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(X_train_input, y_train, verbose=1  )\n",
    "_, test_acc = model.evaluate(X_test_input, y_test, verbose=1)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot loss during training\n",
    "plt.subplot(211)\n",
    "plt.title('Loss')\n",
    "plt.plot(model.history['loss'], label='train')\n",
    "plt.plot(model.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "# plot accuracy during training\n",
    "plt.subplot(212)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(model.history['accuracy'], label='train')\n",
    "plt.plot(model.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMMflHVnGu5hBigJpVDvqkj",
   "collapsed_sections": [
    "vmR01d_FT0Fg",
    "86xwcsXLqaRN"
   ],
   "machine_shape": "hm",
   "name": "Speech_Recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
